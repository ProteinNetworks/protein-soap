{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels from the DeepDrug3D Open Dataset\n",
    "\n",
    "We have 589 heme-binding proteins and 1553 nucleotide-binding proteins. Can we predict which one binds which using SOAP descriptors?\n",
    "\n",
    "Steps:\n",
    "- Generate a tagged xyz file containing all the structures (might be too big?). Save to intermediates/\n",
    "- Create a .labels file giving either \"heme\" or \"nucleotide\" for each PDB. Save to intermediates/\n",
    "- (Optional: split the xyz file into chunks for parallelisation)\n",
    "- Run SOAP++ on the xyz file, using params in input/kernelParams.json\n",
    "- Read the resulting hdf5 file, cluster, colour according to label in the .labels file, run an SVM.\n",
    "- Plot the atomic contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import proteinnetworks\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import palettable\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "from matplotlib.colors import rgb2hex, colorConverter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn import svm\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = proteinnetworks.database.Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these to an xyz file, respecting the ordering and saving it.\n",
    "# (need to use Python2 to get quippy to work)\n",
    "hemeDirName = \"inputs/protein-heme/\"\n",
    "nucleoDirName = \"inputs/protein-nucleotide/\"\n",
    "!/home/will/.local/anaconda3/envs/python2env/bin/python generateXYZfile.py {hemeDirName} {nucleoDirName}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(nucleoDirName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOAPXX\n",
    "\n",
    "Now repeat this analysis with the SOAPXX platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "stub = \"dataBinders/tempATPandEstradiol_tagged\"\n",
    "\n",
    "f = h5py.File(f\"{stub}.hdf5\", \"r\")\n",
    "# f = h5py.File(\"data/tempScop_tagged.hdf5\", \"r\")\n",
    "\n",
    "soapxxScopData = f['kernel']['kernel_mat'].value\n",
    "soapxxScopData = np.nan_to_num(soapxxScopData)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{tempDirectoryName}.labels\") as flines:\n",
    "    scopPaths = [line.strip().split(\"/\")[1][:-4] for line in flines]\n",
    "\n",
    "soapxxScopdf = pd.DataFrame(soapxxScopData, columns=scopPaths)\n",
    "# dictSwap = {i: x for i,x in enumerate(scopPaths)}\n",
    "# scopdf.rename(index=dictSwap, inplace=True)\n",
    "soapxxScopdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soapxxscopg = sns.clustermap(soapxxScopdf, yticklabels=\"auto\", figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, these aren't the same. What happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = hierarchy.distance.pdist(soapxxScopdf)\n",
    "col_linkage = hierarchy.linkage(d, method=\"average\")\n",
    "R = hierarchy.dendrogram(col_linkage, labels=scopPaths, no_plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clusters(dict):\n",
    "    def _repr_html_(self):\n",
    "        html = '<table style=\"border: 0;\">'\n",
    "        for c in self:\n",
    "            hx = rgb2hex(colorConverter.to_rgb(c))\n",
    "            html += '<tr style=\"border: 0;\">' \\\n",
    "            '<td style=\"background-color: {0}; ' \\\n",
    "                       'border: 0;\">' \\\n",
    "            '<code style=\"background-color: {0};\">'.format(hx)\n",
    "            html += c + '</code></td>'\n",
    "            html += '<td style=\"border: 0\"><code>' \n",
    "            html += repr(self[c]) + '</code>'\n",
    "            html += '</td></tr>'\n",
    "        \n",
    "        html += '</table>'\n",
    "        \n",
    "        return html\n",
    "    \n",
    "    \n",
    "def get_cluster_classes(den, label='ivl'):\n",
    "    cluster_idxs = defaultdict(list)\n",
    "    for c, pi in zip(den['color_list'], den['icoord']):\n",
    "        for leg in pi[1:3]:\n",
    "            i = (leg - 5.0) / 10.0\n",
    "            if abs(i - int(i)) < 1e-5:\n",
    "                cluster_idxs[c].append(int(i))\n",
    "    \n",
    "    cluster_classes = Clusters()\n",
    "    for c, l in cluster_idxs.items():\n",
    "        i_l = [den[label][i] for i in l]\n",
    "        cluster_classes[c] = i_l\n",
    "    \n",
    "    return cluster_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterClasses = get_cluster_classes(R)\n",
    "clusterClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scop classes as colourrows\n",
    "from palettable.colorbrewer.qualitative import Dark2_6\n",
    "\n",
    "palette = Dark2_6.hex_colors\n",
    "scopColours = []\n",
    "scopClassLabels = []\n",
    "for path in scopPaths:\n",
    "    if path.endswith(\"estradiol\"):\n",
    "        scopColours.append(palette[0])\n",
    "        scopClassLabels.append(\"estradiol\")\n",
    "    elif path.endswith(\"ATP\"):\n",
    "        scopColours.append(palette[1])\n",
    "        scopClassLabels.append(\"ATP\")\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scopg = sns.clustermap(soapxxScopdf, yticklabels=\"auto\", figsize=(15,15), row_colors=scopColours)\n",
    "# scopg.savefig(\"clusteredSimMatrix.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM stuff\n",
    "\n",
    "- Run SVM using this kernel\n",
    "- Extract the relevant params from the SVM (what they?)\n",
    "- Get the pij and kij from SOAPXX\n",
    "\n",
    "Each atom's contribution to the classifer is given by:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\delta_{Z_J, B} = \\sum_{A} \\alpha_{A} y_{A}  \\sum_{i \\in A}  P_{ij} k_{ij}(A,B) + \\frac{\\beta}{|B|}\n",
    "\\end{equation*}\n",
    "\n",
    "This is the contribution of an individual atomic environment j in structure B to the decision.\n",
    "\n",
    "- $ \\alpha_{A} y_{A}$ are the SVM coefficients, optimised using sklearn.\n",
    "- $\\beta$ is the decision threshold.\n",
    "- These are extracted from the SVM classifier\n",
    "\n",
    "\n",
    "- $P_{ij}$ is the permutation matrix mapping enviromments in A to environments in B.\n",
    "- $k_{ij}(A,B)$ is the SOAP kernel between atomic environments $i \\in A$ and $j \\in B$\n",
    "- These are extracted from SOAPXX\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\\\\\\\n",
    "# import palettable\n",
    "# import json\n",
    "import sklearn.metrics\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def shuffledCopies(a, b):\n",
    "    \"\"\"Shuffled a and b, where a is 1d and b is 2d symmetric\"\"\"\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    shuffled = b[p]\n",
    "    b = shuffled[:,p]\n",
    "    return a[p], b\n",
    "\n",
    "def getSVMScores(path, labels):\n",
    "    \"\"\"\n",
    "    Given a path to a *.k glosim coefficient matrix, and the training\n",
    "    labels, run kernel SVM and print the classification report.\n",
    "    \"\"\"\n",
    "    with open(path) as flines:\n",
    "        glosimData = [line.strip() for line in flines][1:]\n",
    "    glosimData = np.asarray([line.split() for line in glosimData], dtype=float)\n",
    "    # strip nans and infs (sketchy)\n",
    "    glosimData = np.nan_to_num(glosimData)\n",
    "    glosimData[np.where(glosimData>1)] = 1\n",
    "    glosimData[np.where(glosimData<0)] = 0\n",
    "\n",
    "    # Shuffle both the labels and the testMatrix\n",
    "    avgF1Score = []\n",
    "    numberOfTrials = 1000\n",
    "    for i in range(numberOfTrials):\n",
    "        labels, glosimData = shuffledCopies(np.asarray(labels),glosimData)\n",
    "\n",
    "        trainSize = int(len(glosimData)*2/3)\n",
    "        x_train = glosimData[:trainSize, :trainSize]\n",
    "        x_test = glosimData[trainSize:, :trainSize]\n",
    "        y_train = labels[:trainSize]\n",
    "        y_test = labels[trainSize:]\n",
    "        clf = svm.SVC(kernel=\"precomputed\", verbose=False, max_iter=1e9, C=1)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        scores = sklearn.metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "        f1 = scores[\"weighted avg\"][\"f1-score\"]\n",
    "        avgF1Score.append(f1)\n",
    "    return sum(avgF1Score)/len(avgF1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelLabels, kernelData = shuffledCopies(np.asarray(scopClassLabels), soapxxScopData)\n",
    "# kernelLabels, kernelData = (np.asarray(scopClassLabels), soapxxScopData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(len(kernelData)*2/3)\n",
    "x_train = kernelData[:trainSize, :trainSize]\n",
    "x_test = kernelData[trainSize:, :trainSize]\n",
    "y_train = kernelLabels[:trainSize]\n",
    "y_test = kernelLabels[trainSize:]\n",
    "clf = svm.SVC(kernel=\"precomputed\", verbose=False, max_iter=1e9, C=1)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "scores = sklearn.metrics.classification_report(y_test, y_pred) #  output_dict=True)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymol Viz\n",
    "\n",
    "\n",
    "This all needs pipelining properly, but now we have the dzs giving the contribution of each residue to the SVM. \n",
    "\n",
    "Carl makes a density field $ \\rho_B(r) = \\sum_{j \\in B} \\delta_{z_j, B} N \\left( r_j, \\sigma_j \\right)$, i.e a bunch of atom-centred Gaussians of width $\\sigma = 0.5 A$. \n",
    "\n",
    "I think I'll just colour residues using the b-factor then spectrum it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAtomicContributionGivenAtomAndStructure(clf, atomIndex, structureIndex):\n",
    "    \"\"\"\n",
    "    Given a atom index j and a structure index B, get the contribution to the  decision function.\n",
    "    \n",
    "    \\delta_{Z_J, B} = \\sum_{A} \\alpha_{A} y_{A}  \\sum_{i \\in A}  P_{ij} k_{ij}(A,B) + \\frac{\\beta}{|B|}\n",
    "    \"\"\"\n",
    "    \n",
    "    dz = 0.0\n",
    "    # Loop over structures A \n",
    "    for dualcoef, supportIndex in zip(clf.dual_coef_[0], clf.support_):\n",
    "        # Which way round should these indices be?\n",
    "        p_base = np.load(f\"dataBinders/tempATPandEstradiol_tagged_perms_{structureIndex}_{supportIndex}.dat.npy\")\n",
    "        k_base = np.load(f\"dataBinders/tempATPandEstradiol_tagged_kerns_{structureIndex}_{supportIndex}.dat.npy\")\n",
    "        # Loop over each atom i in structure A       \n",
    "        p_base_row = p_base[atomIndex] # should be a row of length (atoms in supportIndex)\n",
    "        k_base_row = k_base[atomIndex] # should be a row of length (atoms in supportIndex)\n",
    "        dz += dualcoef*np.sum(p_base_row*k_base_row)\n",
    "        \n",
    "    sizeOfB = len(p_base) \n",
    "    dz += clf.intercept_ /sizeOfB\n",
    "    return dz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAtomicContributionsGivenDeltaZMappingAndPDBRef(deltaZmapping, pdbRef):\n",
    "    \"\"\"\n",
    "    Given the PDB reference, chain reference and a list of (residueNumber, deltaZ) tuples,\n",
    "    Plot the deltaZs onto the structure.\n",
    "    \"\"\"\n",
    "    PDBData = db.extractPDBFile(pdbRef)\n",
    "\n",
    "    data = np.asarray([line.strip() for line in PDBData\n",
    "                       if line[:4] == \"ATOM\"\n",
    "#                        and line[21] == chainRef\n",
    "                      ])\n",
    "    with open(\"temp.pdb\", \"w\") as flines:\n",
    "        flines.write(\"\\n\".join(data))\n",
    "\n",
    "    dzs = [x[1] for x in deltaZmapping]\n",
    "    \n",
    "    # Make the spectrum symmetric\n",
    "    lowestValue = min(x[0] for x in dzs)\n",
    "    highestValue = max(x[0] for x in dzs)\n",
    "    if lowestValue < 0 and highestValue > 0:\n",
    "        if abs(lowestValue) > highestValue:\n",
    "            highestValue = - lowestValue\n",
    "        elif abs(lowestValue) < highestValue:\n",
    "            lowestValue = -highestValue    \n",
    "\n",
    "    pymolScript = f\"load temp.pdb, {pdbRef}\\n\"\n",
    "    pymolScript += f\"alter {pdbRef}, b=-1\\n\"\n",
    "\n",
    "    for resi,dz in deltaZmapping: # might not work if the residue ids are off\n",
    "        pymolScript += f\"alter resi {resi}, b={dz[0]}\\n\"\n",
    "\n",
    "    pymolScript += f\"\"\"\n",
    "    #formatting\n",
    "    bg_color white\n",
    "    hide all\n",
    "    #show sticks\n",
    "    show cartoon\n",
    "    spectrum b, blue_white_red, minimum={lowestValue}, maximum={highestValue}\n",
    "    set opaque_background=0\n",
    "    set antialias = on\n",
    "    set line_smooth = 1\n",
    "    set depth_cue = 1\n",
    "    set specular = 1\n",
    "    set surface_quality = 1\n",
    "    set stick_quality = 15\n",
    "    set sphere_quality = 2\n",
    "    set ray_trace_fog = 0.8\n",
    "    set light = (-0.2,0,-1)\n",
    "\n",
    "    set ray_shadows, 0\n",
    "    set surface_mode, 1\n",
    "    set cartoon_side_chain_helper,on\n",
    "    zoom\n",
    "    rebuild\n",
    "    \"\"\"\n",
    "    pymolScript += f\"save {pdbRef}.pse \\n\"\n",
    "    pymolScript += f\"\"\"\n",
    "    set ray_trace_mode = 1\n",
    "    png {pdbRef}.png, width=10cm, dpi=300, ray=1\n",
    "    \"\"\"\n",
    "\n",
    "    with open(\"temp.pml\", mode='w') as flines:\n",
    "        flines.write(pymolScript)\n",
    "\n",
    "    # Run quietly\n",
    "    subprocess.run([\"pymol\", \"-c\", \"temp.pml\"])\n",
    "    os.remove(\"temp.pml\")\n",
    "    os.remove(\"temp.pdb\")\n",
    "    display(Image(f\"{pdbRef}.png\"))\n",
    "#     os.remove(f\"{pdbRef}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAtomicContributionsGivenIndexOnSCOPPaths(indexNumber):\n",
    "    \"\"\"\n",
    "    Given an index to SCOPPaths (the list of what label corresponds to what row of the kernel matrix),\n",
    "    find the atomic contributions, then plot them.\n",
    "    \"\"\"\n",
    "    global scopPaths\n",
    "    \n",
    "    pdbRef, chainRef, *_ = scopPaths[indexNumber].split(\"_\")\n",
    "    print(pdbRef, chainRef)\n",
    "    data = !grep {scopPaths[indexNumber]}   dataBinders/tempATPandEstradiol_tagged.xyz -B 1\n",
    "    sizeOfStructure = int(data[0])\n",
    "    dzs= []\n",
    "    for atomIndex in range(sizeOfStructure):\n",
    "        dz = getAtomicContributionGivenAtomAndStructure(clf, atomIndex,indexNumber)\n",
    "        dzs.append(dz)\n",
    "    with open(f\"tempATPandEstradiol/{scopPaths[indexNumber]}.pdb\") as flines:\n",
    "        data = flines.readlines()\n",
    "    residueSequenceNumbers = []\n",
    "    for line in data:\n",
    "        residueSequenceNumbers.append(line[22:26].strip())\n",
    "        \n",
    "        \n",
    "    plotAtomicContributionsGivenDeltaZMappingAndPDBRef(list(zip(residueSequenceNumbers,dzs)), pdbRef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, path in enumerate(scopPaths):\n",
    "    pdbRef, *_ = scopPaths[i].split(\"_\")\n",
    "    plotAtomicContributionsGivenIndexOnSCOPPaths(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}